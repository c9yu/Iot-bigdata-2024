{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 객체탐지\n",
    "\n",
    "#### 개요\n",
    "- 딥러닝의 CNN(외 RCNN 등)와 같은 알고리즘을 통해서 물체를 인식하여 표시하는 기술\n",
    "- 자동차번호판 번호 인식, 화재경보, 교통사고인지, 이상행동파악 등...\n",
    "- CCTV과 같이 접목해서 활용되는 경우가 아주 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리\n",
    "- OpenCV - 최초 인텔에서 개발한 오픈소스 실시간 컴퓨터 비전 라이브러리\n",
    "    - C/C++을 목표로 제작. 크로스 플랫폼    \n",
    "    - 파이썬에 OpenCV가 적용되면서 활성화!\n",
    "    - 카메라 인식 산업에서 대부분 사용되고 있음\n",
    "    - C/C++에서 기본 동작코드 2~300줄이면 파이썬에선 10줄이내로 같은 작업을 할 수 있음\n",
    "\n",
    "- YOLO(PyTorch)\n",
    "    - Not You Only Live Once, You Only Look Once! \n",
    "    - 손쉽게 사용할 수 있는 실시간 객체 탐시 시스템\n",
    "    - 2015년에 출시후 현재 2024년 현재 v8.0 \n",
    "    - OpenCV만 가지고 작업하던 걸, YOLO로 넘어가는 추세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from opencv-python) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Window, Mac 차이가 없음\n",
    "## Raspbarry Pi는 최선버전에서 사용법이 변경되었음.\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 로드\n",
    "## 사막여우 == Fennec Fox\n",
    "img = cv2.imread('./fennec_fox.png')\n",
    "\n",
    "cv2.imshow('Fox', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 현재 웹캠이 동작 안함\n",
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 0~숫자는 카메라번호\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while (cap.isOpened()):  ## True => (cap.isOpened())\n",
    "    ret, img = cap.read() # 실시간으로 화면을 캡쳐 ret(결과정보객체), img(실시간이미지)\n",
    "    if ret == True:\n",
    "        cv2.imshow('youtube mpeg', img) ## 내부적으로 PyQt로 생성되는 GUI창\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'): # 키보드 q를 클릭하면\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() # 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이미지 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fennec_fox.png')\n",
    "\n",
    "cv2.imshow('Original', img) ## 일반 이미지\n",
    "# cv2.waitKey(0) \n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "height, width = img.shape[0], img.shape[1]\n",
    "## 정수입력 width/2 => float 문제\n",
    "half_img = cv2.resize(gray, (int(width/2), int(height/2)))\n",
    "# cv2.imshow('Gray', gray) ## 흑백 변환\n",
    "cv2.imshow('half', half_img)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 0~숫자는 카메라번호\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while (cap.isOpened()):   \n",
    "    ret, img = cap.read() # 실시간으로 화면을 캡쳐 ret(결과정보객체) 보통 사용하지 않아서 _로 변경, img(실시간이미지)\n",
    "    if ret == True:\n",
    "        # cv2.imshow('youtube mpeg', img) ## 내부적으로 PyQt로 생성되는 GUI창\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  ## 컬러 -> 흑백으로\n",
    "        half = cv2.resize(gray, (int(width/2), int(height/2))) ## 사이즈를 반으로 축소\n",
    "        cv2.imshow('youtube gray', half)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'): # 키보드 q를 클릭하면\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() # 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 포토샵등의 이미지, 프리미어등의 동영상 처리하는 프로그램에서 사용하는 거의 대부분의 기능이 OpenCV에 포함되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './mbc_news.mp4'\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(video_path) # 0~숫자는 카메라번호\n",
    "\n",
    "while (cap.isOpened()):    \n",
    "    ret, img = cap.read() # 실시간으로 화면을 캡쳐 ret(결과정보객체) 보통 사용하지 않아서 _로 변경, img(실시간이미지)\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "\n",
    "        # 얼굴인식\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            half,\n",
    "            scaleFactor=2.0,\n",
    "            minNeighbors=5,\n",
    "            minSize=(10,10)\n",
    "        )\n",
    "        ## 찾은 얼굴 위치 표시\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(half,(x,y),(x+w,y+h),(0,255,255), 2)\n",
    "            roi_color = half[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.imshow('youtube mpeg', half) ## 내부적으로 PyQt로 생성되는 GUI창\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'): # 키보드 q를 클릭하면\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() # 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (15.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pafy in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (0.5.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_dl in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (2021.12.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downYoutube(videourl, path):\n",
    "    yt = YouTube(videourl)\n",
    "    yt = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "    if not os.path.exists(path): os.makedirs(path) ## 폴더가 없으면 생성\n",
    "\n",
    "    yt.download(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m youtube_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=zxxfvP8-lrU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdownYoutube\u001b[49m\u001b[43m(\u001b[49m\u001b[43myoutube_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m, in \u001b[0;36mdownYoutube\u001b[1;34m(videourl, path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownYoutube\u001b[39m(videourl, path):\n\u001b[0;32m      2\u001b[0m     yt \u001b[38;5;241m=\u001b[39m YouTube(videourl)\n\u001b[1;32m----> 3\u001b[0m     yt \u001b[38;5;241m=\u001b[39m \u001b[43myt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreams\u001b[49m\u001b[38;5;241m.\u001b[39mfilter(progressive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, file_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39morder_by(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolution\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc()\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path): os\u001b[38;5;241m.\u001b[39mmakedirs(path) \u001b[38;5;66;03m## 폴더가 없으면 생성\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     yt\u001b[38;5;241m.\u001b[39mdownload(path)\n",
      "File \u001b[1;32mc:\\Sources\\Iot-bigdata-2024\\gpu_env\\Lib\\site-packages\\pytube\\__main__.py:296\u001b[0m, in \u001b[0;36mYouTube.streams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Interface to query both adaptive (DASH) and progressive streams.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m:rtype: :class:`StreamQuery <StreamQuery>`.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_availability()\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StreamQuery(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmt_streams\u001b[49m)\n",
      "File \u001b[1;32mc:\\Sources\\Iot-bigdata-2024\\gpu_env\\Lib\\site-packages\\pytube\\__main__.py:176\u001b[0m, in \u001b[0;36mYouTube.fmt_streams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmt_streams\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmt_streams \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 176\u001b[0m stream_manifest \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mapply_descrambler(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreaming_data\u001b[49m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# If the cached js doesn't work, try fetching a new js file\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# https://github.com/pytube/pytube/issues/1054\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Sources\\Iot-bigdata-2024\\gpu_env\\Lib\\site-packages\\pytube\\__main__.py:160\u001b[0m, in \u001b[0;36mYouTube.streaming_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvid_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreamingData\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbypass_age_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvid_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreamingData\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Sources\\Iot-bigdata-2024\\gpu_env\\Lib\\site-packages\\pytube\\__main__.py:257\u001b[0m, in \u001b[0;36mYouTube.bypass_age_gate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Attempt to update the vid_info by bypassing the age gate.\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m innertube \u001b[38;5;241m=\u001b[39m InnerTube(\n\u001b[0;32m    253\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANDROID_EMBED\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    254\u001b[0m     use_oauth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_oauth,\n\u001b[0;32m    255\u001b[0m     allow_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_oauth_cache\n\u001b[0;32m    256\u001b[0m )\n\u001b[1;32m--> 257\u001b[0m innertube_response \u001b[38;5;241m=\u001b[39m \u001b[43minnertube\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m playability_status \u001b[38;5;241m=\u001b[39m innertube_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayabilityStatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# If we still can't access the video, raise an exception\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# (tier 3 age restriction)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Sources\\Iot-bigdata-2024\\gpu_env\\Lib\\site-packages\\pytube\\innertube.py:448\u001b[0m, in \u001b[0;36mInnerTube.player\u001b[1;34m(self, video_id)\u001b[0m\n\u001b[0;32m    444\u001b[0m query \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideoId\u001b[39m\u001b[38;5;124m'\u001b[39m: video_id,\n\u001b[0;32m    446\u001b[0m }\n\u001b[0;32m    447\u001b[0m query\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_params)\n\u001b[1;32m--> 448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Sources\\Iot-bigdata-2024\\gpu_env\\Lib\\site-packages\\pytube\\innertube.py:390\u001b[0m, in \u001b[0;36mInnerTube._call_api\u001b[1;34m(self, endpoint, query, data)\u001b[0m\n\u001b[0;32m    386\u001b[0m         headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccess_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    388\u001b[0m headers\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader)\n\u001b[1;32m--> 390\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[1;32mc:\\Sources\\Iot-bigdata-2024\\gpu_env\\Lib\\site-packages\\pytube\\request.py:37\u001b[0m, in \u001b[0;36m_execute_request\u001b[1;34m(url, method, headers, data, timeout)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Langs\\Python311\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Langs\\Python311\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\DEV\\Langs\\Python311\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\DEV\\Langs\\Python311\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Langs\\Python311\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\DEV\\Langs\\Python311\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "youtube_url = 'https://www.youtube.com/watch?v=zxxfvP8-lrU'\n",
    "downYoutube(youtube_url, 'video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (8.2.76)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (3.9.1.post1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.4.0+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (0.19.0+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: colorama in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\sources\\iot-bigdata-2024\\gpu_env\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# YOLO 설치\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.76 🚀 Python-3.11.5 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Sources\\Iot-bigdata-2024\\day08\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 27.6ms\n",
      "Speed: 6.7ms preprocess, 27.6ms inference, 337.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Sources\\Iot-bigdata-2024\\runs\\detect\\predict2\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "## 콘솔창에서 테스트 하는 방법, 트레이닝한 이미지 처리 모델\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Sources\\Iot-bigdata-2024\\day08\\20190417_194709.jpg: 384x640 1 bottle, 1 cup, 1 bowl, 1 tv, 1 mouse, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# 이미지와 openCV 물체 감지\n",
    "model = YOLO(model='./yolov8n.pt')\n",
    "\n",
    "result = model('./20190417_194709.jpg')\n",
    "plots = result[0].plot()\n",
    "height, width = plots.shape[0], plots.shape[1]\n",
    "last = cv2.resize(plots, (800, 450))\n",
    "cv2.imshow('yolo', last)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 영상 분석 실시간도 가능\n",
    "classNames = [\n",
    "              \"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 22.9ms\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Argument 'fontFace' is required to be an integer\n>  - Argument 'fontFace' is required to be an integer\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m         color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m     34\u001b[0m         thickness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 36\u001b[0m         \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mputText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontScale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthickness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOLOv8\u001b[39m\u001b[38;5;124m'\u001b[39m, half)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Argument 'fontFace' is required to be an integer\n>  - Argument 'fontFace' is required to be an integer\n"
     ]
    }
   ],
   "source": [
    "video_path = './Mumbai_traffic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 숫자는 CCTV,웹캠 등 실시간 영상\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "        # YOLO로 물체검출 시작\n",
    "        results = model(half, stream=True)\n",
    "\n",
    "        ## 결과표시 like OpenCV 얼굴검출\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                cv2.rectangle(half, (x1,y1), (x2,y2), (0,255,255), 2) # 검출된 물체 박스 그리기\n",
    "\n",
    "                ## 정확도 계산, Class name\n",
    "                accuracy = (box.conf[0]/100)*100\n",
    "                index = int(box.cls[0])\n",
    "                # print(f'Class name : {classNames[index]} / Accuracy : {accuracy:.2f}')\n",
    "                title = f'{classNames[index]}, {accuracy:.2f}'\n",
    "\n",
    "                ## 물체 박스 위에 종류와 정확도 출력\n",
    "                org = [x1, y1]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 0.5\n",
    "                color = (0,255,255)\n",
    "                thickness = 2\n",
    "\n",
    "                cv2.putText(half, title, org, fontScale, color, thickness)\n",
    "\n",
    "        cv2.imshow('YOLOv8', half)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
